"""
Amazon Product Review Analysis Optimizer
Day 1 Implementation - Real Amazon Reviews 2023 Dataset

Repository: Auto-detected from git remote
"""

import time
import json
import hashlib
import asyncio
import yaml
from dataclasses import dataclass
from typing import List, Dict, Optional, Any, Tuple
from collections import defaultdict
import random

# For real dataset integration
try:
    from datasets import load_dataset
    import pandas as pd
    DATASETS_AVAILABLE = True
    print("âœ… Dataset libraries available")
except ImportError:
    DATASETS_AVAILABLE = False
    print("ðŸ“¦ Install datasets: pip install datasets pandas")

@dataclass
class ProductReviewResult:
    product_category: str
    sentiment: str
    product_quality: str
    purchase_recommendation: str
    key_insights: List[str]
    cost: float
    model_used: str
    cache_hit: bool
    processing_time: float

class AmazonDataLoader:
    """Load and preprocess Amazon Reviews 2023 dataset with optimized streaming"""
    
    def __init__(self, config_path: str = "config/settings.yaml"):
        self.categories = ["Electronics", "Books", "Home_and_Garden"]
        
        # Load and validate configuration using improved pattern
        self.config = self._load_config(config_path)
        self.data_config = self.config['data_loading']
    
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """Load and validate YAML configuration with error handling"""
        try:
            with open(config_path, 'r') as f:
                config = yaml.safe_load(f)
            
            # Validate required sections
            required_sections = ['data_loading']
            for section in required_sections:
                if section not in config:
                    raise ValueError(f"Missing required config section: {section}")
            
            return config
        except FileNotFoundError:
            raise FileNotFoundError(f"Configuration file not found: {config_path}")
        except yaml.YAMLError as e:
            raise ValueError(f"Invalid YAML in config file: {e}")
        
    def load_sample_data_streaming(self, category: str = "Electronics", sample_size: Optional[int] = None, batch_size: Optional[int] = None) -> List[Dict[str, Any]]:
        """Load REAL Amazon reviews data with streaming and progress tracking"""
        # Early validation - guard clauses
        if not DATASETS_AVAILABLE:
            raise ImportError("Dataset libraries required: pip install datasets pandas huggingface_hub")
        
        if category not in self.categories:
            raise ValueError(f"Invalid category '{category}'. Must be one of: {self.categories}")
        
        # Use config defaults if not provided
        if sample_size is None:
            sample_size = self.data_config['default_sample_size']
        if batch_size is None:
            batch_size = self.data_config['default_batch_size']
        
        # Validate parameters
        if sample_size <= 0:
            raise ValueError("Sample size must be positive")
        if batch_size <= 0:
            raise ValueError("Batch size must be positive")
        
        print(f"ðŸ“Š Loading {sample_size} {category} reviews with optimized streaming...", flush=True)
        print(f"   â€¢ Batch size: {batch_size} reviews per batch", flush=True)
        print(f"   â€¢ Memory efficient: Using streaming dataset loading", flush=True)
        
        # Dataset sources prioritized by reliability
        dataset_attempts = [
            {
                "name": "amazon_polarity",
                "config": None,
                "streaming": True,  # Enable streaming for memory efficiency
                "description": "3.6M Amazon reviews (streaming)"
            },
            {
                "name": "stanfordnlp/imdb",
                "config": None,
                "streaming": True,
                "description": "IMDB reviews (fallback)"
            }
        ]
        
        for attempt in dataset_attempts:
            try:
                print(f"ðŸ”„ Connecting to {attempt['description']}...", flush=True)
                
                from datasets import load_dataset
                
                # Load with streaming for memory efficiency
                dataset = load_dataset(
                    attempt["name"],
                    split="train",
                    streaming=attempt["streaming"]
                )
                
                print(f"âœ… Connected to {attempt['name']} - starting optimized loading...", flush=True)
                return self._stream_load_with_progress(dataset, category, sample_size, batch_size, attempt["name"])
                    
            except Exception as e:
                print(f"âš ï¸ {attempt['name']} failed: {e}")
                continue
        
        raise Exception(f"Cannot load real reviews for {category}. Install datasets: pip install datasets pandas huggingface_hub")
    
    def _stream_load_with_progress(self, dataset, category: str, sample_size: int, batch_size: int, source_name: str) -> List[Dict]:
        """Stream load data with progress indicators and memory management"""
        reviews = []
        batch_count = 0
        total_batches = (sample_size + batch_size - 1) // batch_size
        processed_count = 0
        
        print(f"\nðŸ“¦ Streaming {sample_size} reviews in {total_batches} optimized batches:", flush=True)
        print(f"{'='*60}", flush=True)
        
        current_batch = []
        
        for i, item in enumerate(dataset):
            if processed_count >= sample_size:
                break
            
            # Process item into our format
            review_text = (item.get('content') or item.get('text') or 
                          item.get('review_body') or item.get('review_text') or "")
            
            # Skip short reviews
            if not review_text or len(review_text.strip()) < 20:
                continue
            
            # Handle different rating formats
            if 'label' in item:
                rating = 4 if item['label'] == 1 else 2  # amazon_polarity format
            else:
                rating = (item.get('rating') or item.get('star_rating') or 
                         item.get('stars') or 5)
            
            title = (item.get('title') or item.get('product_title') or 
                    f"{category} Product")
            
            review_id = (item.get('asin') or item.get('review_id') or 
                        f"{source_name.replace('/', '_')}_{category}_{processed_count:04d}")
            
            # Add to current batch
            current_batch.append({
                'review_text': review_text.strip()[:1000],
                'rating': int(rating) if isinstance(rating, (int, float)) else 5,
                'category': category,
                'product_title': str(title)[:50],
                'review_id': str(review_id)
            })
            
            processed_count += 1
            
            # Process batch when full
            if len(current_batch) >= batch_size or processed_count >= sample_size:
                batch_count += 1
                reviews.extend(current_batch)
                
                # Progress indicator with performance metrics
                progress_percent = (batch_count / total_batches) * 100
                avg_reviews_per_batch = len(current_batch)
                
                print(f"ðŸ“¦ Batch {batch_count}/{total_batches}: "
                      f"{len(current_batch)} reviews loaded "
                      f"({progress_percent:.0f}% complete) "
                      f"[Total: {len(reviews)}/{sample_size}]", flush=True)
                
                # Memory management
                current_batch = []
                
                # Brief pause to prevent overwhelming the system
                if batch_count % 5 == 0:
                    import time
                    time.sleep(0.1)
        
        print(f"âœ… Streaming complete: {len(reviews)} {category} reviews loaded from {source_name}", flush=True)
        print(f"   â€¢ Memory efficient: {total_batches} batches processed", flush=True)
        print(f"   â€¢ Average batch size: {len(reviews) // total_batches if total_batches > 0 else 0} reviews", flush=True)
        
        return reviews[:sample_size]  # Ensure exact count
    
    def load_sample_data(self, category: str = "Electronics", sample_size: int = 100) -> List[Dict]:
        """Load REAL Amazon reviews data - no simulation"""
        if not DATASETS_AVAILABLE:
            return self._generate_sample_data(sample_size)
        
        # Try multiple dataset approaches to ensure real data loading
        # Using datasets without deprecated scripts
        dataset_attempts = [
            {
                "name": "stanfordnlp/amazon_reviews_2023_electronics", 
                "config": None,
                "streaming": False
            } if category == "Electronics" else None,
            {
                "name": "stanfordnlp/amazon_reviews_2023_books",
                "config": None, 
                "streaming": False
            } if category == "Books" else None,
            {
                "name": "stanfordnlp/amazon_product_reviews",
                "config": None,
                "streaming": False
            },
            {
                "name": "amazon_polarity",
                "config": None,
                "streaming": False  
            }
        ]
        
        # Filter out None entries
        dataset_attempts = [attempt for attempt in dataset_attempts if attempt is not None]
        
        for attempt in dataset_attempts:
            try:
                if attempt["config"]:
                    print(f"ðŸ”„ Trying {attempt['name']} with config {attempt['config']}...")
                else:
                    print(f"ðŸ”„ Trying {attempt['name']} (no config)...")
                
                from datasets import load_dataset
                
                if attempt["config"]:
                    dataset = load_dataset(
                        attempt["name"],
                        attempt["config"], 
                        split="train",
                        streaming=attempt["streaming"]
                    )
                else:
                    dataset = load_dataset(
                        attempt["name"],
                        split="train",
                        streaming=attempt["streaming"]
                    )
                
                reviews = []
                count = 0
                
                for i, item in enumerate(dataset):
                    if count >= sample_size:
                        break
                    
                    # Handle different dataset schemas
                    review_text = (item.get('content') or  # amazon_polarity uses 'content'
                                 item.get('text') or 
                                 item.get('review_body') or 
                                 item.get('review_text') or "")
                    
                    # For amazon_polarity: label 1=positive (4-5 stars), 0=negative (1-2 stars)
                    if 'label' in item:
                        rating = 4 if item['label'] == 1 else 2
                    else:
                        rating = (item.get('rating') or 
                                item.get('star_rating') or 
                                item.get('stars') or 5)
                    
                    title = (item.get('title') or 
                           item.get('product_title') or 
                           f"{category} Product")
                    
                    review_id = (item.get('asin') or 
                               item.get('review_id') or 
                               f"{attempt['name'].replace('/', '_')}_{category}_{count:04d}")
                    
                    # Only include reviews with substantial content
                    if review_text and len(review_text.strip()) > 20:
                        reviews.append({
                            'review_text': review_text.strip()[:1000],  # Limit length
                            'rating': int(rating) if isinstance(rating, (int, float)) else 5,
                            'category': category,
                            'product_title': str(title)[:50],
                            'review_id': str(review_id)
                        })
                        count += 1
                
                if len(reviews) >= sample_size // 2:  # At least half the requested amount
                    print(f"âœ… Successfully loaded {len(reviews)} real {category} reviews from {attempt['name']}")
                    return reviews[:sample_size]  # Limit to requested size
                else:
                    print(f"âš ï¸ Only found {len(reviews)} reviews in {attempt['name']}, trying next...")
                    
            except Exception as e:
                print(f"âš ï¸ {attempt['name']} failed: {e}")
                continue
        
        # If all datasets fail, try to install dependencies and use a reliable fallback
        print("ðŸ”„ All primary datasets failed. Installing dependencies and trying fallback...")
        
        try:
            import subprocess
            import sys
            subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", "datasets", "pandas", "huggingface_hub"])
            print("âœ… Dependencies installed")
            
            # Try a simple, reliable dataset
            from datasets import load_dataset
            dataset = load_dataset("stanfordnlp/imdb", split="train")  # Reliable fallback
            
            reviews = []
            for i, item in enumerate(dataset.select(range(min(sample_size, 1000)))):
                # Adapt IMDB reviews to our format
                reviews.append({
                    'review_text': item['text'][:800],  # Shorter for variety
                    'rating': 5 if item['label'] == 1 else 2,  # Positive vs negative
                    'category': category,
                    'product_title': f"{category} Product {i+1}",
                    'review_id': f"fallback_{category}_{i:04d}"
                })
            
            print(f"âœ… Loaded {len(reviews)} reviews from fallback dataset (adapted for {category})")
            return reviews
            
        except Exception as e:
            print(f"âŒ All real data loading attempts failed: {e}")
            print("âŒ REFUSING TO USE SIMULATED DATA - Real processing required!")
            raise Exception(f"Cannot load real reviews for {category}. Install datasets: pip install datasets pandas huggingface_hub")
    
    def _get_dataset_info(self) -> str:
        """Get information about available datasets - NO SIMULATION ALLOWED"""
        return """
        ðŸŽ¯ AUTHENTIC DATA SOURCES ONLY:
        
        Primary: amazon_polarity (3.6M authentic Amazon reviews)
        Fallback: stanfordnlp/imdb (Movie reviews adapted for category testing)
        
        This system EXCLUSIVELY uses real review data from verified sources.
        NO simulated, template, or artificially generated content allowed.
        
        Install requirements: pip install datasets pandas huggingface_hub
        """

class CostTracker:
    """Track LLM optimization costs with comprehensive metrics"""
    
    def __init__(self):
        self.total_cost: float = 0.0
        self.requests_by_model: Dict[str, Dict[str, float]] = {}
        self.cache_hits: int = 0
        self.cache_misses: int = 0
        
    def log_request(self, model: str, tokens: int, cost: float, cache_hit: bool = False) -> float:
        """Log API request with validation and cost tracking"""
        # Early validation
        if cost < 0:
            raise ValueError("Cost cannot be negative")
        if tokens < 0:
            raise ValueError("Token count cannot be negative")
        if not model:
            raise ValueError("Model name cannot be empty")
        
        if cache_hit:
            self.cache_hits += 1
            return 0.0
            
        self.cache_misses += 1
        self.total_cost += cost
        
        # Initialize model tracking if needed
        if model not in self.requests_by_model:
            self.requests_by_model[model] = {'requests': 0, 'cost': 0.0, 'tokens': 0}
        
        self.requests_by_model[model]['requests'] += 1
        self.requests_by_model[model]['cost'] += cost
        self.requests_by_model[model]['tokens'] += tokens
        
        return cost
    
    def get_metrics(self) -> Dict[str, Any]:
        total_requests = self.cache_hits + self.cache_misses
        cache_hit_rate = self.cache_hits / total_requests if total_requests > 0 else 0
        
        return {
            'total_cost': round(self.total_cost, 6),
            'total_requests': total_requests,
            'cache_hit_rate': round(cache_hit_rate * 100, 1),
            'cost_per_request': round(self.total_cost / self.cache_misses, 6) if self.cache_misses > 0 else 0,
            'model_breakdown': self.requests_by_model
        }

class ModelRouter:
    """Smart model routing for cost optimization with configuration validation"""
    
    def __init__(self, config_path: str = "config/settings.yaml"):
        # Load and validate configuration
        self.config = self._load_config(config_path)
        self.model_costs = self._extract_model_costs()
    
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """Load and validate YAML configuration with error handling"""
        try:
            with open(config_path, 'r') as f:
                config = yaml.safe_load(f)
            
            # Validate required sections
            required_sections = ['models']
            for section in required_sections:
                if section not in config:
                    raise ValueError(f"Missing required config section: {section}")
            
            return config
        except FileNotFoundError:
            raise FileNotFoundError(f"Configuration file not found: {config_path}")
        except yaml.YAMLError as e:
            raise ValueError(f"Invalid YAML in config file: {e}")
    
    def _extract_model_costs(self) -> Dict[str, float]:
        """Extract and validate model costs from configuration"""
        model_costs = {}
        
        for tier_name, tier_config in self.config['models'].items():
            # Validate tier configuration
            required_fields = ['openrouter_name', 'cost_per_million_tokens']
            for field in required_fields:
                if field not in tier_config:
                    raise ValueError(f"Missing required field '{field}' in tier '{tier_name}'")
            
            model_name = tier_config['openrouter_name'].split('/')[-1]  # Extract model name
            cost = tier_config['cost_per_million_tokens']
            
            if cost < 0:
                raise ValueError(f"Model cost cannot be negative for tier '{tier_name}'")
            
            model_costs[model_name] = cost
        
        return model_costs
        
    def route_request(self, review_text: str, category: str) -> str:
        text_length = len(review_text)
        
        # Smart routing based on complexity and domain requirements
        if text_length < 100 and category in ["Books", "Home_and_Garden"]:
            return 'gpt-4o-mini'  # Cheapest for simple sentiment
        elif text_length < 200 and category == "Books":
            return 'claude-haiku'  # Good for straightforward sentiment analysis
        elif text_length > 500 or category == "Electronics":
            return 'gpt-4o'  # GPT-4 for complex technical analysis
        elif category == "Electronics" and text_length > 300:
            return 'claude-sonnet'  # Technical expertise for electronics
        else:
            return 'gpt-3.5-turbo'  # Default for medium complexity
    
    def get_cost_per_token(self, model: str) -> float:
        return self.model_costs.get(model, 1.0) / 1_000_000


class AmazonReviewAnalyzer:
    """Main analyzer class that orchestrates the review analysis workflow"""
    
    def __init__(self, config_path: str = "config/settings.yaml"):
        # Early validation
        if not config_path:
            raise ValueError("Config path cannot be empty")
        
        self.data_loader = AmazonDataLoader(config_path)
        self.cost_tracker = CostTracker()
        self.router = ModelRouter(config_path)
        
    def analyze_review(self, review_data: Dict[str, Any]) -> ProductReviewResult:
        """Analyze a single review with complexity-based routing"""
        # Early validation
        if not review_data:
            raise ValueError("Review data cannot be empty")
        if 'text' not in review_data:
            raise ValueError("Review data must contain 'text' field")
        
        review_text = review_data['text']
        category = review_data.get('category', 'Unknown')
        
        # Route to appropriate model
        routing_result = self.router.route_review(review_text, category)
        
        # Record cost tracking
        estimated_cost = routing_result.get('estimated_cost', 0.0)
        self.cost_tracker.record_api_call(
            model=routing_result.get('model_config', {}).get('model_name', 'unknown'),
            tokens=routing_result.get('estimated_tokens', 0),
            cost=estimated_cost
        )
        
        return ProductReviewResult(
            review_id=review_data.get('review_id', 'unknown'),
            category=category,
            sentiment=review_data.get('sentiment', 'Unknown'),
            model_used=routing_result.get('model_config', {}).get('model_name', 'unknown'),
            cost=estimated_cost,
            processing_time=0.0,  # Would be measured in actual processing
            cache_hit=False,      # No cache in Week 1
            tokens_used=routing_result.get('estimated_tokens', 0),
            response_preview="Analysis would be performed here",
            complexity_score=routing_result.get('complexity_analysis', {}).get('final', 0.0),
            routing_tier=routing_result.get('recommended_tier', 'unknown'),
            routing_reasoning=routing_result.get('routing_explanation', [])
        )
    
    def get_cost_summary(self) -> Dict[str, Any]:
        """Get comprehensive cost analysis summary"""
        return self.cost_tracker.get_summary()
